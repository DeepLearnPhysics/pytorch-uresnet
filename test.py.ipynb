{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to test commands for semantic segmentation data and network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "import os,sys,commands,time\n",
    "\n",
    "# ROOT/larcv\n",
    "import ROOT\n",
    "from larcv import larcv\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "#import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "# Set path to larcvdataset repository\n",
    "# to get it: clone https://github.com/deeplearnphysics/larcvdataset\n",
    "# uncommen the next two lines to use it\n",
    "#_PATH_TO_LARCVDATASET_REPO_=\"location of \"\n",
    "#sys.path.append(_PATH_TO_LARCVDATASET_REPO_)\n",
    "import larcvdataset\n",
    "\n",
    "# Set path to pytorch-uresnet\n",
    "# to get it: clone https://github.com/deeplearnphysics/pytorch-uresnet\n",
    "# uncommen the next two lines to use it\n",
    "#_PATH_TO_PYTORCHURESNET_REPO_=\"location of \"\n",
    "#sys.path.append(_PATH_TO_PYTORCHURESNET_REPO_)\n",
    "import uresnet\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions of LArCVDataset and UResNet\n",
    "\n",
    "If helpful, you can dump out information about the LArCVDataset and UResNet classes.\n",
    "\n",
    "* LArCVDataset: provides interface to data within a larcv root file\n",
    "* UResNet: UNet with resnet modules. (cite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to see\n",
    "#help(larcvdataset.LArCVDataset)\n",
    "#help(uresnet.UResNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an instance of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = uresnet.UResNet(inplanes=16,input_channels=1,num_classes=3,showsizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment dump network definition\n",
    "# print net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up on the GPU\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss function\n",
    "class PixelWiseNLLLoss(nn.modules.loss._WeightedLoss):\n",
    "    def __init__(self,weight=None, size_average=True, ignore_index=-100 ):\n",
    "        super(PixelWiseNLLLoss,self).__init__(weight,size_average)\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduce = False\n",
    "        self.mean = torch.mean.cuda()\n",
    "\n",
    "    def forward(self,predict,target,pixelweights):\n",
    "        \"\"\"\n",
    "        predict: (b,c,h,w) tensor with output from logsoftmax\n",
    "        target:  (b,h,w) tensor with correct class\n",
    "        pixelweights: (b,h,w) tensor with weights for each pixel\n",
    "        \"\"\"\n",
    "        _assert_no_grad(target)\n",
    "        _assert_no_grad(pixelweights)\n",
    "        # reduce for below is false, so returns (b,h,w)\n",
    "        pixelloss = F.nll_loss(predict,target, self.weight, self.size_average, self.ignore_index, self.reduce)\n",
    "        return self.mean(pixelloss*pixelweights)\n",
    "\n",
    "lossfcn = PixelWiseNLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Configuration File\n",
    "\n",
    "The LArCVDataset class is basically a wrapper around larcv.ThreadFiller. \n",
    "To configure it, one needs to provide a configuration file, which we write here.\n",
    "\n",
    "Remember to point to the location of the input larcv root file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write threadfiller io configuration file\n",
    "ioconfig = \"\"\"ThreadProcessorTest: {\n",
    "  Verbosity:3\n",
    "  NumThreads: 2\n",
    "  NumBatchStorage: 2\n",
    "  RandomAccess: true\n",
    "  InputFiles: [\"/home/taritree/working/dlphysics/pytorch-uresnet/practice_test_2k.root\"]\n",
    "  ProcessName: [\"imagetest\",\"segmenttest\"]\n",
    "  ProcessType: [\"BatchFillerImage2D\",\"BatchFillerImage2D\"]\n",
    "  ProcessList: {\n",
    "    imagetest: {\n",
    "      Verbosity:3\n",
    "      ImageProducer: \"data\"\n",
    "      Channels: [2]\n",
    "      EnableMirror: false\n",
    "    }\n",
    "    segmenttest: {\n",
    "      Verbosity:3\n",
    "      ImageProducer: \"segment\"\n",
    "      Channels: [2]\n",
    "      EnableMirror: false\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "with open(\"test_threadfiller.cfg\",'w') as f:\n",
    "    print >> f,ioconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an instance of LArCVDataset using our configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create larcvdataset instance\n",
    "io = larcvdataset.LArCVDataset(\"test_dataloader.cfg\",\"ThreadProcessorTest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start up the LArCVDataset\n",
    "\n",
    "When started, the object will launch threads that are responsible for taking data from the root file and putting it into a dictionary of numpy arrays.\n",
    "\n",
    "When we start we, we need to pass in the batchsize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.start(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a batch\n",
    "\n",
    "We use the `[ ]` operator to get our first batch. Note: the argument is currently meaningless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the batch: returns a dictionary of numpy arrays\n",
    "data = io[0]\n",
    "print data.keys()\n",
    "\n",
    "# get the individual elements\n",
    "# img: numpy array with the image\n",
    "# seg: numpy array with the class labels\n",
    "img = data[\"imagetest\"]\n",
    "seg = data[\"segmenttest\"]\n",
    "\n",
    "# we want to reshape the arrays into (batch, channels, H, W)\n",
    "img = img.reshape((1,1,256,256))\n",
    "seg = seg.reshape((1,256,256))\n",
    "wgt = np.ones( (1,256,256) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImgAndLabels(image2d,label2d):\n",
    "    # Dump images\n",
    "    fig, (ax0,ax1) = plt.subplots(1, 2, figsize=(10,10), facecolor='w')\n",
    "    ax0.imshow(image2d, interpolation='none', cmap='jet', origin='lower')\n",
    "    ax1.imshow(label2d, interpolation='none', cmap='jet', origin='lower',vmin=0., vmax=3.1)\n",
    "    ax0.set_title('Data',fontsize=20,fontname='Georgia',fontweight='bold')\n",
    "    #ax0.set_xlim(xlim)\n",
    "    #ax0.set_ylim(ylim)\n",
    "    ax1.set_title('Label',fontsize=20,fontname='Georgia',fontweight='bold')\n",
    "    #ax1.set_xlim(xlim)\n",
    "    #ax1.set_ylim(ylim)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "showImgAndLabels(img.reshape((256,256)),seg.reshape((256,256)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array to torch array\n",
    "timage  = torch.from_numpy(img).cuda()\n",
    "ttarget = torch.from_numpy(seg).cuda()\n",
    "tweight = torch.from_numpy(wgt).cuda()\n",
    "\n",
    "# convert to torch autograd variable\n",
    "image_var = torch.autograd.Variable(timage)\n",
    "target_var = torch.autograd.Variable(ttarget)\n",
    "weight_var = torch.autograd.Variable(tweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push through the net to test it\n",
    "\n",
    "s = time.time()\n",
    "output = net(image_var)\n",
    "s = time.time()-s\n",
    "print \"forward time: \",s\n",
    "# note: first time is slow, about 600 ms, (as network allocating mem?)\n",
    "#       next forward pass is about 15 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "s = time.time()\n",
    "loss = lossfcn(output,target_var,weight_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop the LArCVDataset interface\n",
    "\n",
    "When stopped. The threads resonsible for reading in data are terminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
